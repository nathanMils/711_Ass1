{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ed1c0c-db1b-4083-851d-4630feb4eac1",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea438307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "# Pandas for data preparation and Numpty for DP logic\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5b91ef-324a-449c-af88-0e5537fbaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RawData\n",
    "rawData = pd.read_csv(\"../Data/Almond.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7941c62d-ee2e-4a8f-adaa-df78165d7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Length, Width and Thickness for imputation\n",
    "# Aswell as Area\n",
    "p_LWT = rawData[['Length (major axis)','Width (minor axis)','Thickness (depth)','Area']].copy()\n",
    "# Set Area to NaN where length is NaN\n",
    "p_LWT['Area'] = np.where(p_LWT['Length (major axis)'].notna(),\n",
    "                          p_LWT['Area'],\n",
    "                          np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be3625-65da-431d-996b-d538fb3710f2",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "Roundness is a derived feature with:\n",
    "Roundness = 4 * area/(_pi * length^2)\n",
    "\n",
    "So Roundness is NaN where Length is NaN, however area is not.\n",
    "So to make roundness more consistent I created a new column where area is NaN where length is NaN and then impute the area.\n",
    "This area with then be used to calculate the Roundness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d604b9d-c98d-4c03-a656-1f82ae6671d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sklearn libraries\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae736f6c-d92c-4ee5-8a6a-6ee600a00b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple imputation using sklearn\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "d_LWT_imputed = pd.DataFrame(imputer.fit_transform(p_LWT), columns=p_LWT.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14504d4-9464-46ff-8a25-b00c1dd695e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Roundness using the imputed Area when there is length\n",
    "d_LWT_imputed['Roundness'] = 4 * d_LWT_imputed['Area'] / (np.pi * d_LWT_imputed['Length (major axis)']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95088790-5336-4179-8ca4-55f0aae35510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelavent features\n",
    "p_proc = rawData.drop('Id',axis=1)\n",
    "# Use imputed data to calculate derived features\n",
    "p_proc[['Length (major axis)','Width (minor axis)','Thickness (depth)','Roundness']] = d_LWT_imputed[['Length (major axis)','Width (minor axis)','Thickness (depth)','Roundness']]\n",
    "p_proc['Aspect Ratio'] = p_proc['Length (major axis)']/p_proc['Width (minor axis)']\n",
    "p_proc['Eccentricity'] = (1 - (p_proc['Width (minor axis)']/p_proc['Length (major axis)'])**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442fc264-14b6-4aae-93a4-9217431baca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Input(X)/Output(Y)\n",
    "X = p_proc[['Length (major axis)','Width (minor axis)','Thickness (depth)','Area','Perimeter','Roundness','Solidity','Compactness','Aspect Ratio','Eccentricity','Extent','Convex hull(convex area)']]\n",
    "Y = p_proc['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7002215c-64cf-458b-8db7-d78adab3f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Labeler\n",
    "labeler = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb531e2-5aec-445c-846e-5235a02a1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for NN\n",
    "# Pretty sure this shit is just magic\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1cc5837-ed14-43e0-8d3c-047396822fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,Y -> X_tensor,Y_tensor\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(labeler.fit_transform(Y), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6393f26f-3bc4-4ea4-8473-75f2a5e72300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into training, validation and testing\n",
    "# Train + (Val|Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, test_size=0.3, stratify=y_tensor ,random_state=21)\n",
    "# Val + Test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "255cad05-0c05-4c67-940b-64ed6f5b958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply training data transformation across all three sets for consistency\n",
    "mean = X_train.mean(dim=0)\n",
    "std = X_train.std(dim=0)\n",
    "\n",
    "X_train_norm = (X_train - mean)/std\n",
    "X_val_norm = (X_val - mean)/std\n",
    "X_test_norm = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345a396-61ff-4f0d-9cf5-45b0645160f3",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd6ac314-84cd-4d87-9101-7a286d229b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningAlgo(opt):\n",
    "    if opt == 0:\n",
    "        return optim.Adam\n",
    "    elif opt == 1:\n",
    "        return optim.Rprop\n",
    "    else:\n",
    "        return optim.SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80f713-44c1-4eaf-8b19-e88b7b986b2c",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4d2a1d6-a444-4859-8d22-f31e8050b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate  =0.001\n",
    "num_epochs = 500\n",
    "batch_size = 34\n",
    "no_layers = 3\n",
    "\n",
    "# Objective Function\n",
    "obj_func = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_opt = 0\n",
    "# 0 - Admin\n",
    "# 1 - Rprop\n",
    "# 2 - SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed260b-6865-42ec-a433-79af59a2e68a",
   "metadata": {},
   "source": [
    "## Neural Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cecdf33c-fc0e-457a-a8ff-4e39934fadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NathansWeirdNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NathansWeirdNN, self).__init__()\n",
    "        self.l1 = nn.Linear(12, 64)                 # First fully connected \n",
    "        self.l2 = nn.Linear(64, 32)\n",
    "        self.l3 = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Func.relu(self.l1(x))\n",
    "        x = Func.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f10255e8-0ace-4e7c-a3a0-2f37d41d797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NathansWeirdNN()\n",
    "# Learning Algorithm\n",
    "learn_algo = learningAlgo(learning_opt)(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a532278-672d-4e4d-a23c-9d86161d8797",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "678b0392-e031-413b-acdf-44b11d9e27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching Function\n",
    "def batch(X_ten, Y_ten):\n",
    "    num = X_ten.size(0)\n",
    "    for n in range(0, num, batch_size):\n",
    "        m = min(n + batch_size, num)\n",
    "        yield X_ten[n:m], Y_ten[n:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "538763d8-0291-4463-bc2a-0e8fa4842435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def training(model, num_epochs, X, y, learning_algo, obj_function):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for bX, bY in batch(X,y):\n",
    "            learning_algo.zero_grad()\n",
    "            output = model(bX)\n",
    "            loss = obj_function(output, bY)\n",
    "            loss.backward()\n",
    "            learning_algo.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d4741e8-e05d-4956-a595-4684667da356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.0036,   4.8230,   1.7619],\n",
      "        [ -6.9266,   2.9357,  -1.8914],\n",
      "        [  2.1070, -10.7628, -13.5088],\n",
      "        ...,\n",
      "        [ -3.0207,  -1.4687,   0.5859],\n",
      "        [-13.4486,  -0.6655,   3.8905],\n",
      "        [ -0.1855,  -2.8423,  -4.4657]])\n",
      "tensor([1, 1, 0, 2, 2, 2, 0, 0, 0, 0, 1, 0, 1, 2, 1, 1, 2, 2, 2, 2, 0, 1, 0, 1,\n",
      "        0, 0, 2, 1, 2, 1, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 1, 1,\n",
      "        0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 1,\n",
      "        2, 2, 1, 1, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2, 2, 1,\n",
      "        2, 1, 2, 0, 0, 1, 2, 0, 2, 2, 0, 2, 1, 0, 0, 2, 0, 2, 1, 1, 0, 1, 0, 0,\n",
      "        2, 0, 2, 2, 2, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 2, 0, 1, 2, 1, 2, 2,\n",
      "        0, 2, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 2, 2, 1, 2,\n",
      "        0, 2, 2, 0, 0, 1, 1, 0, 2, 2, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1,\n",
      "        2, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 1, 0,\n",
      "        0, 2, 1, 2, 1, 0, 0, 2, 2, 0, 1, 2, 1, 2, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2,\n",
      "        1, 1, 0, 2, 1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        2, 0, 1, 2, 0, 1, 1, 0, 0, 2, 0, 1, 2, 0, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1,\n",
      "        2, 0, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 1, 0, 2, 2, 1, 2, 2,\n",
      "        1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1, 2, 1, 1, 2, 1, 0, 2, 1, 2, 2, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 2, 1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2,\n",
      "        2, 0, 0, 2, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1, 0, 1, 2, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 2, 2, 0, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0,\n",
      "        2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 1, 1, 0])\n",
      "Test ERROR: 0.7057347297668457\n",
      "Test Accuracy: 80.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "def evaluate(model,X,y,obj_function):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X)\n",
    "        \n",
    "    error = obj_function(output, y)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == y).sum().item()\n",
    "    accuracy = correct / len(y)\n",
    "    \n",
    "    print(f\"Test ERROR: {loss.item()}\")\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "822b272a-6d9e-4872-a51c-5d872a8b2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(model, num_epochs, X_train_norm, y_train, learn_algo, obj_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a7642-d694-49f7-832b-e9915f0b07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, X_test_norm, y_test, obj_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
